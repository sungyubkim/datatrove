# GPT OSS 120B ë°ì´í„°ì…‹ ë³€í™˜ ì™„ë£Œ ë³´ê³ ì„œ

**ì‘ì—… ì™„ë£Œì¼**: 2025-01-04
**ë³€í™˜ëœ ìƒ˜í”Œ ìˆ˜**: 4,000 (Train: 3,920 / Test: 80)
**ë°ì´í„° ì†ŒìŠ¤**: `rlla_gpt`
**í”„ë¡œì íŠ¸**: DataTrove (ì›ë³¸: ToolRL)

---

## âœ… ì™„ë£Œëœ ì‘ì—…

### 1. ë°ì´í„° ë³€í™˜ âœ…
- **íŒŒì¼**: `examples/convert_toolrl_to_gpt_oss.py`
- **ìƒíƒœ**: ì„±ê³µ (0 errors)
- **ì¶œë ¥**: `examples/data/rlla_4k_gpt/train.parquet`, `test.parquet`

**ë³€í™˜ ë§¤í•‘**:
```
<think>...</think>           â†’ <|start|>assistant<|channel|>analysis<|message|>...<|end|>
<tool_call>{json}</tool_call> â†’ <|start|>assistant to=functions.{name}<|channel|>commentary json<|message|>{params}<|call|>
<response>...</response>      â†’ <|start|>assistant<|channel|>final<|message|>...<|return|>
```

### 2. Reward í•¨ìˆ˜ âœ…
- **íŒŒì¼**: `src/datatrove/utils/reward_score/toolrl_gpt_oss.py`
- **í…ŒìŠ¤íŠ¸**: 7/7 test cases passed
- **ìœ„ì¹˜**: datatrove reward score module

**Reward êµ¬ì„±**:
- Format reward: 0.0 ~ 1.0 (GPT OSS í† í° êµ¬ì¡° ê²€ì¦)
- Correctness reward: -3.0 ~ 3.0 (Tool call ì •í™•ë„)
- Length reward: 0.0 ~ 1.0 (ì„ íƒì , `WITHLENGTH=1`ë¡œ í™œì„±í™”)

### 3. Tokenization ê²€ì¦ âœ…
- **Tokenizer**: `openai/gpt-oss-120b` ë¡œë“œ ì„±ê³µ
- **Vocab size**: 200,019 tokens
- **Special tokens**: ëª¨ë‘ ì¸ì‹ë¨

**Special Tokens**:
| Token | ID | ìš©ë„ |
|-------|-----|------|
| `<\|start\|>` | 200006 | ë©”ì‹œì§€ ì‹œì‘ |
| `<\|end\|>` | 200007 | ë©”ì‹œì§€ ì¢…ë£Œ |
| `<\|message\|>` | 200008 | ë‚´ìš© êµ¬ë¶„ì |
| `<\|channel\|>` | 200005 | ì±„ë„ ì§€ì • |
| `<\|call\|>` | 200012 | Tool í˜¸ì¶œ |
| `<\|return\|>` | 200002 | ìƒì„± ì¢…ë£Œ |

### 4. Token ê¸¸ì´ í†µê³„ âœ…

**Prompt Tokens** (System + User):
- í‰ê· : 953.8 tokens
- ìµœì†Œ: 584 tokens
- ìµœëŒ€: 3,991 tokens
- 2048 ì´ˆê³¼: 27 samples (0.7%)

**Ground Truth Tokens** (Assistant Response):
- í‰ê· : 83.2 tokens
- ìµœì†Œ: 28 tokens
- ìµœëŒ€: 685 tokens
- 1024 ì´ˆê³¼: 0 samples (0%)

**Total Tokens** (Prompt + Response):
- í‰ê· : 1,037.0 tokens
- ìµœì†Œ: 623 tokens
- ìµœëŒ€: 4,201 tokens

**í•´ì„**:
- âœ… ëŒ€ë¶€ë¶„ì˜ ìƒ˜í”Œì´ í•™ìŠµ ì œí•œ(2048 prompt + 1024 response) ë‚´ì— ìˆìŒ
- âœ… Ground truthëŠ” 100% ì œí•œ ë‚´
- âš ï¸ 27ê°œ ìƒ˜í”Œ(0.7%)ì˜ promptê°€ 2048 ì´ˆê³¼ â†’ í•™ìŠµ ì‹œ truncation í•„ìš”

### 5. ë°ì´í„° íŒ¨í„´ ë¶„ì„ âœ…

**Training Set** (3,920 samples):
- Analysis channel: 3,920 (100.0%)
- Tool calls: 3,447 (87.9%)
- Final responses: 473 (12.1%)

**Test Set** (80 samples):
- Analysis channel: 80 (100.0%)
- Tool calls: 71 (88.8%)
- Final responses: 9 (11.2%)

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼

### Reward Function Tests
```
âœ… Perfect Tool Call Match:      Format=1.0, Correctness=3.0
âœ… Partial Parameter Match:      Format=1.0, Correctness=1.0
âœ… Wrong Tool Name:              Format=1.0, Correctness=-3.0
âœ… Missing Analysis Channel:     Format=0.0, Correctness=3.0
âœ… Multiple Tool Calls:          Format=1.0, Correctness=3.0
âœ… Final Response Only:          Format=1.0, Correctness=0.0
âœ… Completely Wrong Format:      Format=0.0, Correctness=-3.0
```

### Real Dataset Samples
```
âœ… Sample 0 (Response only):     Total=1.0
âœ… Sample 2 (Tool call):         Total=4.0 (perfect match)
âœ… Sample 100 (Tool call):       Total=4.0 (perfect match)
```

---

## ğŸ“ íŒŒì¼ êµ¬ì¡° (DataTrove)

```
ğŸ“¦ datatrove/
â”œâ”€â”€ src/datatrove/
â”‚   â””â”€â”€ utils/reward_score/
â”‚       â””â”€â”€ toolrl_gpt_oss.py           # âœ… GPT OSS reward í•¨ìˆ˜
â”‚
â”œâ”€â”€ tests/utils/reward_score/
â”‚   â”œâ”€â”€ test_gpt_oss_tokenization.py    # âœ… Tokenization í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test_gpt_oss_reward.py          # âœ… Reward í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test_gpt_oss_standalone.py      # âœ… ë…ë¦½ ì‹¤í–‰ reward í…ŒìŠ¤íŠ¸
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ convert_toolrl_to_gpt_oss.py    # âœ… ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
    â”œâ”€â”€ GPT_OSS_CONVERSION_SUMMARY.md   # ì´ íŒŒì¼
    â””â”€â”€ data/
        â””â”€â”€ rlla_4k_gpt/                # âœ… ë³€í™˜ëœ ë°ì´í„°ì…‹
            â”œâ”€â”€ train.parquet           # 3,920 samples
            â”œâ”€â”€ test.parquet            # 80 samples
            â””â”€â”€ README*.md              # ë°ì´í„°ì…‹ ë¬¸ì„œ
```

---

## ğŸš€ ì‚¬ìš© ë°©ë²•

### ë°ì´í„° ì¬ë³€í™˜ (í•„ìš”ì‹œ)
```bash
cd datatrove/examples

# ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš© (ToolRL â†’ datatrove/examples/data/)
python convert_toolrl_to_gpt_oss.py

# ì»¤ìŠ¤í…€ ê²½ë¡œ ì‚¬ìš©
python convert_toolrl_to_gpt_oss.py \
  --input-dir /path/to/rlla_4k \
  --output-dir /path/to/output

# ìì„¸í•œ ì‚¬ìš©ë²• í™•ì¸
python convert_toolrl_to_gpt_oss.py --help
```

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
cd datatrove

# Reward í•¨ìˆ˜ í…ŒìŠ¤íŠ¸ (GPU ë¶ˆí•„ìš”)
python tests/utils/reward_score/test_gpt_oss_standalone.py

# ë˜ëŠ”
python tests/utils/reward_score/test_gpt_oss_reward.py

# Tokenization í…ŒìŠ¤íŠ¸ (GPU ë¶ˆí•„ìš”, transformers í•„ìš”)
pip install transformers jinja2
python tests/utils/reward_score/test_gpt_oss_tokenization.py
```

### Pythonì—ì„œ ì§ì ‘ ì‚¬ìš©
```python
from datatrove.utils.reward_score import toolrl_gpt_oss

# GPT OSS í˜•ì‹ì˜ solutionê³¼ ground truth í‰ê°€
solution_str = """<|start|>user<|message|>Test query<|end|>
<|start|>assistant<|channel|>analysis<|message|>I should use the esg tool<|end|>
<|start|>assistant to=functions.esg<|channel|>commentary json<|message|>{"symb":"MSFT"}<|call|>"""

ground_truth = """<|start|>assistant<|channel|>analysis<|message|>I should use the esg tool<|end|>
<|start|>assistant to=functions.esg<|channel|>commentary json<|message|>{"symb":"MSFT"}<|call|>"""

# Compute score
score, format_score, correctness_score, length_score = toolrl_gpt_oss.compute_score(
    solution_str,
    ground_truth,
    step=0
)

print(f"Total: {score}, Format: {format_score}, Correctness: {correctness_score}")
```

### Reward ë³€í˜• í™œì„±í™”
Reward í•¨ìˆ˜ëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì œì–´ë©ë‹ˆë‹¤:
```bash
# ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ (ToolRL í•™ìŠµ ì‹œ ì ìš©)
export WITHLENGTH=1          # Length reward ì¶”ê°€
export CORRECTMAX1=1         # Correctnessë¥¼ Â±1.0ìœ¼ë¡œ ìŠ¤ì¼€ì¼
export SCHEDULEREWARD=1      # ë™ì  reward ìŠ¤ì¼€ì¼ë§
export REFINEDREWARD=1       # ì—„ê²©í•œ ë§¤ì¹­
export INTERMEDIATEREWARD=1  # ì¤‘ê°„ ë‹¨ê³„ reward
export COARSEREWARD=1        # ê±°ì¹œ reward

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
python tests/utils/reward_score/test_gpt_oss_reward.py
```

---

## ğŸ“Š ì„±ëŠ¥ ê¸°ëŒ€ì¹˜

### Token íš¨ìœ¨ì„±
- XML íƒœê·¸ (`<think>`) â†’ ~3 tokens (ì¼ë°˜ tokenizer)
- GPT OSS tokens (`<|channel|>analysis`) â†’ 2 special tokens
- **ì˜ˆìƒ ì ˆê°**: ìƒ˜í”Œë‹¹ ~10-15% ì ì€ í† í° ìˆ˜

### í˜¸í™˜ì„±
- âœ… GRPO (Group Relative Policy Optimization)
- âœ… PPO (Proximal Policy Optimization)
- âœ… vLLM rollout
- âœ… Tensor Parallelism
- âœ… FSDP (Fully Sharded Data Parallel)
- âœ… DataTrove reward scoring system

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### Prompt Length ì´ˆê³¼ ìƒ˜í”Œ
27ê°œ ìƒ˜í”Œ(0.7%)ì´ 2048 token ì œí•œì„ ì´ˆê³¼í•©ë‹ˆë‹¤.

**í•´ê²° ë°©ë²•**:
1. Training configì—ì„œ `data.max_prompt_length=4096`ìœ¼ë¡œ ì¦ê°€
2. ë˜ëŠ” í•™ìŠµ ì‹œ ìë™ truncation í—ˆìš©
3. ë˜ëŠ” í•´ë‹¹ ìƒ˜í”Œ ì œì™¸

**ê¶Œì¥**: ëŒ€ë¶€ë¶„ì˜ ìƒ˜í”Œì´ ì œí•œ ë‚´ì´ë¯€ë¡œ ìë™ truncation í—ˆìš©

### System Prompt
GPT OSS tokenizerëŠ” ìë™ìœ¼ë¡œ system message ì•ì— default instructionì„ ì¶”ê°€í•©ë‹ˆë‹¤:
```
<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.
Knowledge cutoff: 2024-06
Current date: 2025-11-04
...
```

**ì˜í–¥**: Prompt tokenì´ ì˜ˆìƒë³´ë‹¤ ì•½ê°„ ì¦ê°€í•  ìˆ˜ ìˆìŒ

---

## ğŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### "No module named 'toolrl_gpt_oss'"
**í•´ê²°**: DataTroveê°€ ì œëŒ€ë¡œ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
```bash
cd datatrove
pip install -e .

# ë˜ëŠ” uv ì‚¬ìš©
uv pip install -e .
```

### Import ì˜¤ë¥˜
**í•´ê²°**: ì˜¬ë°”ë¥¸ import ê²½ë¡œ ì‚¬ìš©
```python
# ì˜¬ë°”ë¥¸ ê²½ë¡œ
from datatrove.utils.reward_score import toolrl_gpt_oss

# ì˜ëª»ëœ ê²½ë¡œ (ToolRL)
from verl.utils.reward_score import rlla_gpt_oss  # âŒ
```

### Dataset path not found
**í•´ê²°**: ìƒëŒ€ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
```python
from pathlib import Path

# í…ŒìŠ¤íŠ¸ íŒŒì¼ì—ì„œ dataset ê²½ë¡œ
test_dir = Path(__file__).parent
dataset_path = test_dir / '../../../examples/data/rlla_4k_gpt/train.parquet'
```

### Format score always 0
**í•´ê²°**: Responseì— GPT OSS tokens í¬í•¨ í™•ì¸
- `<|start|>assistant`
- `<|channel|>`
- ì ì ˆí•œ terminator (`<|end|>`, `<|call|>`, `<|return|>`)

---

## ğŸ“ˆ ê²€ì¦ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [x] ë°ì´í„° ë³€í™˜ ì™„ë£Œ (4,000 samples, 0 errors)
- [x] Data source ì—…ë°ì´íŠ¸ (`rlla` â†’ `rlla_gpt`)
- [x] Reward í•¨ìˆ˜ DataTroveë¡œ ì´ë™
- [x] ëª¨ë“  í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ DataTroveë¡œ ì´ë™
- [x] Import ê²½ë¡œ ì—…ë°ì´íŠ¸ (verl â†’ datatrove)
- [x] GPT OSS tokenizer ë¡œë“œ
- [x] Special tokens ì¸ì‹ (6/6 tokens)
- [x] Chat template ì ìš©
- [x] Token ê¸¸ì´ í†µê³„ ë¶„ì„
- [x] ë¬¸ì„œí™” ì—…ë°ì´íŠ¸
- [x] í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ê²€ì¦

---

## ğŸ¯ ToolRLì—ì„œ ì‚¬ìš©í•˜ê¸°

ì´ ë°ì´í„°ì…‹ê³¼ reward í•¨ìˆ˜ë¥¼ ToolRL í•™ìŠµì— ì‚¬ìš©í•˜ë ¤ë©´:

1. **ToolRL í”„ë¡œì íŠ¸ì—ì„œ DataTrove reward í•¨ìˆ˜ import**:
   ```python
   # verl/trainer/main_ppo.py ë˜ëŠ” í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ
   import sys
   sys.path.insert(0, '/path/to/datatrove/src')
   from datatrove.utils.reward_score import toolrl_gpt_oss as rlla_gpt_oss
   ```

2. **ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •**:
   ```bash
   # train_grpo_gpt_oss.sh
   DATA_DIR="/path/to/datatrove/examples/data/rlla_4k_gpt"
   ```

3. **í•™ìŠµ ì‹œì‘** (GPU í•„ìš”):
   ```bash
   bash train_grpo_gpt_oss.sh
   ```

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- **Reward í•¨ìˆ˜**: `src/datatrove/utils/reward_score/toolrl_gpt_oss.py`
- **ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸**: `examples/convert_toolrl_to_gpt_oss.py`
- **ë°ì´í„°ì…‹ ìƒì„¸**: `examples/data/rlla_4k_gpt/README*.md`
- **GPT OSS tokenizer**: https://huggingface.co/openai/gpt-oss-120b

---

## âœ… ìµœì¢… ìƒíƒœ

**ëª¨ë“  ì‘ì—… ì™„ë£Œ ë° DataTroveë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ** âœ…

- ë°ì´í„° ë³€í™˜: âœ… 4,000 samples
- Reward í•¨ìˆ˜: âœ… 7/7 tests passed
- Tokenization: âœ… 3,920 samples verified
- DataTrove í†µí•©: âœ… Complete
- í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸: âœ… 3ê°œ íŒŒì¼ ì´ë™ ì™„ë£Œ
- ë¬¸ì„œí™”: âœ… Complete

**DataTroveì—ì„œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë˜ëŠ” ToolRLì—ì„œ í•™ìŠµì— ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**

---

## ğŸ“ ë³€ê²½ ì´ë ¥

### v2.0 (2025-11-04)
- DataTrove í”„ë¡œì íŠ¸ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
- ëª¨ë“  import ê²½ë¡œ ì—…ë°ì´íŠ¸ (verl â†’ datatrove)
- í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì¬êµ¬ì„±
- ë¬¸ì„œ ì—…ë°ì´íŠ¸

### v1.0 (2025-01-04)
- ì´ˆê¸° ToolRL í”„ë¡œì íŠ¸ì—ì„œ ì‘ì„±
- GPT OSS í˜•ì‹ ë³€í™˜ ì™„ë£Œ
- Reward í•¨ìˆ˜ ë° í…ŒìŠ¤íŠ¸ ì‘ì„±

---

**ì‘ì„±ì**: Claude Code
**ë²„ì „**: 2.0
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-11-04
